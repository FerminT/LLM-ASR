{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tedlium_path = '/home/ftravi/Downloads/es-es/data'\n",
    "mls_path = '/home/ftravi/Downloads/mls_spanish_opus'\n",
    "model_id = \"openai/whisper-large-v3\" # opciones: openai/whisper-medium openai/whisper-small openai/whisper-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "device = \"cpu\"\n",
    "torch_dtype = torch.float32\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from yaml import safe_load\n",
    "\n",
    "def extract_audio_metadata(path):\n",
    "    info = sf.info(path)\n",
    "    return {'filename':path, 'samplerate': info.samplerate, 'duration': info.duration}\n",
    "\n",
    "def read_mls(path):\n",
    "    all_dfs = []\n",
    "    for split in ['test']:\n",
    "        df = pd.read_csv(Path(path,split,'transcripts.txt'),delimiter='\\t',header=None,names=['idx','transcription'])\n",
    "        all_wavs = Path(path,split,'audio').rglob('*.opus')\n",
    "        wav_mapping = {x.stem: str(x.resolve()) for x in all_wavs}\n",
    "        df['filename'] = df['idx'].apply(lambda x: wav_mapping[x])\n",
    "        df['partition'] = split\n",
    "        df['start'] = 0\n",
    "        all_dfs.append(df)\n",
    "    df = pd.concat(all_dfs)\n",
    "    metadatas = []\n",
    "    for f in tqdm(df['filename']):\n",
    "        metadatas.append(extract_audio_metadata(f))\n",
    "    metadatas = pd.DataFrame(metadatas)\n",
    "    df = pd.merge(df, metadatas, left_on='filename', right_on='filename')\n",
    "    df['dataset'] = 'mls'\n",
    "    return df\n",
    "\n",
    "def read_tedlium(path):\n",
    "    all_dfs = []\n",
    "    for split in ['test']:\n",
    "        txt_path, wav_path = Path(path, split, 'txt'), Path(path, split, 'wav')\n",
    "        transcripts = load_tedlium_transcripts(txt_path / f'{split}.es')\n",
    "        with (txt_path / f'{split}.yaml').open('r') as f:\n",
    "            audio_metadata = safe_load(f)\n",
    "        for i in tqdm(range(len(audio_metadata))):\n",
    "            audio = audio_metadata[i]\n",
    "            audio['transcription'] = transcripts[i]\n",
    "            audio['wav'] = audio['wav'].replace('wav', 'flac')\n",
    "            audio['partition'] = split if split != 'valid' else 'dev'\n",
    "            audio['filename'] = str((wav_path / audio['wav']).resolve())\n",
    "            audio['samplerate'] = extract_audio_metadata(audio['filename'])['samplerate']\n",
    "            audio['start'] = audio['offset']\n",
    "            del audio['wav']\n",
    "            del audio['offset']\n",
    "            del audio['speaker_id']\n",
    "        split_df = pd.DataFrame(audio_metadata).reset_index(names='idx')\n",
    "        all_dfs.append(split_df)\n",
    "    df = pd.concat(all_dfs)\n",
    "    df['dataset'] = 'tedlium'\n",
    "    return df\n",
    "        \n",
    "def load_tedlium_transcripts(file_path):\n",
    "    transcripts = []\n",
    "    with file_path.open('r') as f:\n",
    "        for line in f:\n",
    "            line = line.lower()[:-2]\n",
    "            transcripts.append(line)\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mls = read_mls(mls_path)\n",
    "df_tedlium = read_tedlium(tedlium_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from whisper_normalizer.basic import BasicTextNormalizer\n",
    "from jiwer import wer, cer\n",
    "from pandas import DataFrame\n",
    "from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "\n",
    "def evaluate_df(df):\n",
    "    results = {'gt': [], 'pred': [], 'wer': [], 'cer': []}\n",
    "    text_normalizer = Normalizer(input_case='cased', lang='es')\n",
    "    second_normalizer = BasicTextNormalizer()\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        start = row['start']\n",
    "        duration = row['duration']\n",
    "        filename = row['filename']\n",
    "        og_transcription = second_normalizer(text_normalizer.normalize(row['transcription']))\n",
    "        wav, _ = librosa.core.load(filename, offset=start, duration=duration)\n",
    "        transcription = pipe(wav, generate_kwargs={\"language\": \"spanish\"})\n",
    "        transcription = second_normalizer(text_normalizer.normalize(transcription['text']))\n",
    "        results['gt'].append(og_transcription)\n",
    "        results['pred'].append(transcription)\n",
    "        results['wer'].append(wer(og_transcription, transcription))\n",
    "        results['cer'].append(cer(og_transcription, transcription))\n",
    "    return DataFrame(results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_id.split('/')[-1]\n",
    "df_tedlium_results = evaluate_df(df_tedlium)\n",
    "df_tedlium_results.to_csv(f'tedlium_results_{model_name}.csv')\n",
    "df_mls_results = evaluate_df(df_mls)\n",
    "df_mls_results.to_csv(f'mls_results_{model_name}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
